{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "\n",
    "def read_labels(file_name):\n",
    "    # open file\n",
    "    with open(file_name, mode='rb') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # read number to test and amount of labels containted in this file\n",
    "    [magic_number, labels_count] = struct.unpack('>ii', file_content[0:8])\n",
    "\n",
    "    # if the magic_number does not match, something went wrong\n",
    "    if magic_number != 0x0801:\n",
    "        print(\"Magic Number does not match. (0x{:02X})\".format(magic_number))\n",
    "        return\n",
    "\n",
    "    # create format string\n",
    "    # this string defines the layout of file_content\n",
    "    # '>' = big endian\n",
    "    # 'B' = unsigned byte\n",
    "    labels_format_string = '>{}B'.format(labels_count)\n",
    "\n",
    "    # itnerpret file_content as specified by label_format_string\n",
    "    labels = np.array(struct.unpack(labels_format_string, file_content[8:]))\n",
    "    print(\"Labels loaded.\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "def read_images(file_name):\n",
    "    # open file\n",
    "    with open(file_name, mode='rb') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # load number to test against, number of images, row count and column count\n",
    "    [magic_number, images_count, rows,\n",
    "     cols] = struct.unpack('>iiii', file_content[0:16])\n",
    "\n",
    "    # if magic_number does not match, something went wrong\n",
    "    if magic_number != 0x0803:\n",
    "        print(\"Magic Number does not match. (0x{:02X})\".format(magic_number))\n",
    "        return\n",
    "\n",
    "    # create image array\n",
    "    images = np.zeros((images_count, rows, cols), np.ubyte)\n",
    "    # define format string of one image row (image in mnist files is presented row wise)\n",
    "    row_format_string = '>{}B'.format(cols)\n",
    "    # define start variable of actual content\n",
    "    start = 16\n",
    "    for image in range(0, images_count):\n",
    "        for row in range(0, rows):\n",
    "            end = start + cols  # define end of image row\n",
    "            # load image row\n",
    "            images[image, row] = np.array(\n",
    "                struct.unpack(row_format_string, file_content[start:end]))\n",
    "            start = end  # set start to next image\n",
    "\n",
    "        print(\"Images loaded: {}\".format(image + 1), end='\\r')\n",
    "\n",
    "    print()\n",
    "    return images\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    # read input arguments\n",
    "    training_path = argv[0]\n",
    "    test_path = argv[1]\n",
    "    epochs = int(argv[2])\n",
    "\n",
    "    # read training data\n",
    "    training_labels = read_labels(\n",
    "        \"{}/train-labels-idx1-ubyte\".format(training_path))\n",
    "    training_images = read_images(\n",
    "        \"{}/train-images-idx3-ubyte\".format(training_path))\n",
    "\n",
    "    # define model data\n",
    "    classes_count = 10\n",
    "    keep_rate = 0.8\n",
    "\n",
    "    # define training constraints\n",
    "    batch_size = 64\n",
    "\n",
    "    # create actual neural network\n",
    "    model = create_model(classes_count, keep_rate)\n",
    "\n",
    "    # train neural network\n",
    "    model.fit(training_images,\n",
    "              training_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size)\n",
    "\n",
    "    # load test data\n",
    "    test_labels = read_labels(\"{}/t10k-labels-idx1-ubyte\".format(test_path))\n",
    "    test_images = read_images(\"{}/t10k-images-idx3-ubyte\".format(test_path))\n",
    "\n",
    "    # test model against test data\n",
    "    result = model.evaluate(test_images, test_labels)\n",
    "\n",
    "    print(\"Loss: {}\\nAccuracy: {}\".format(result[0], result[1]))\n",
    "\n",
    "\n",
    "def create_model(classes_count, keep_rate):\n",
    "    # define layers\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(1 - keep_rate),\n",
    "        tf.keras.layers.Dense(classes_count, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # compile model using information about training\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
